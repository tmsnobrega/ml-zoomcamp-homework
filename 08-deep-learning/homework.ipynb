{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af32520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f934e21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Download data (run only once)\n",
    "# !wget https://github.com/SVizor42/ML_Zoomcamp/releases/download/straight-curly-data/data.zip\n",
    "# !unzip data.zip -d data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "740307d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f09fe1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "class HairTypeCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Conv layer: input channels=3, output channels=32, kernel=3x3\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=3,\n",
    "            out_channels=32,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=0\n",
    "        )\n",
    "\n",
    "        # MaxPool layer: reduces H,W by factor of 2\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # After conv + pool, we flatten and feed into FC\n",
    "        # We must compute the flattened size:\n",
    "        # Input: (3, 200, 200)\n",
    "        # After conv1 (kernel=3, no padding): (32, 198, 198)\n",
    "        # After maxpool (2x2): (32, 99, 99)\n",
    "        flattened_size = 32 * 99 * 99  \n",
    "\n",
    "        self.fc1 = nn.Linear(flattened_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 1)  # Single output for binary classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)  # raw logits\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be2393d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 20073473\n"
     ]
    }
   ],
   "source": [
    "# Calculate total number of parameters\n",
    "model = HairTypeCNN()\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f'Total number of parameters: {total_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d6b6796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Check for GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d66d1dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data transformations\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((200, 200)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "test_transforms = train_transforms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3814604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "train_dataset = datasets.ImageFolder(\"data/data/train\", transform=train_transforms)\n",
    "validation_dataset = datasets.ImageFolder(\"data/data/test\", transform=test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8001665c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=20, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=20, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2cc1833c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "class HairTypeCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=0)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # compute flattened size: (3,200,200)->conv->(32,198,198)->pool->(32,99,99)\n",
    "        flattened = 32 * 99 * 99\n",
    "\n",
    "        self.fc1 = nn.Linear(flattened, 64)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)  # raw logits\n",
    "        return x\n",
    "\n",
    "model = HairTypeCNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fcf26854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.002, momentum=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e525903b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.6654, Acc: 0.6262, Val Loss: 0.6102, Val Acc: 0.6617\n",
      "Epoch 2/10, Loss: 0.5479, Acc: 0.7087, Val Loss: 0.6303, Val Acc: 0.6468\n",
      "Epoch 3/10, Loss: 0.4858, Acc: 0.7638, Val Loss: 0.6991, Val Acc: 0.5970\n",
      "Epoch 4/10, Loss: 0.4806, Acc: 0.7650, Val Loss: 0.6097, Val Acc: 0.7015\n",
      "Epoch 5/10, Loss: 0.4403, Acc: 0.7863, Val Loss: 0.6215, Val Acc: 0.6517\n",
      "Epoch 6/10, Loss: 0.3493, Acc: 0.8500, Val Loss: 0.6453, Val Acc: 0.6716\n",
      "Epoch 7/10, Loss: 0.3005, Acc: 0.8775, Val Loss: 0.6953, Val Acc: 0.6816\n",
      "Epoch 8/10, Loss: 0.2746, Acc: 0.8938, Val Loss: 0.6370, Val Acc: 0.7214\n",
      "Epoch 9/10, Loss: 0.2119, Acc: 0.9225, Val Loss: 0.6828, Val Acc: 0.7114\n",
      "Epoch 10/10, Loss: 0.1419, Acc: 0.9525, Val Loss: 0.8263, Val Acc: 0.6965\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 10\n",
    "history = {'acc': [], 'loss': [], 'val_acc': [], 'val_loss': []}\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        labels = labels.float().unsqueeze(1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    epoch_acc = correct_train / total_train\n",
    "    history['loss'].append(epoch_loss)\n",
    "    history['acc'].append(epoch_acc)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in validation_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            labels = labels.float().unsqueeze(1)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_running_loss += loss.item() * images.size(0)\n",
    "            predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "    val_epoch_loss = val_running_loss / len(validation_dataset)\n",
    "    val_epoch_acc = correct_val / total_val\n",
    "\n",
    "    history['val_loss'].append(val_epoch_loss)\n",
    "    history['val_acc'].append(val_epoch_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, \"\n",
    "          f\"Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}, \"\n",
    "          f\"Val Loss: {val_epoch_loss:.4f}, Val Acc: {val_epoch_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeaba5d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Median training accuracy across 10 epochs: 0.818125\n"
     ]
    }
   ],
   "source": [
    "# Calculate median training accuracy across epochs\n",
    "median_acc = statistics.median(history['acc'])\n",
    "print(\"Median training accuracy across 10 epochs:\", median_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa36eaa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation of training loss: 0.1622458634918277\n"
     ]
    }
   ],
   "source": [
    "# Calculate standard deviation of training loss across epochs\n",
    "train_loss_std = statistics.stdev(history['loss'])\n",
    "print(\"Standard deviation of training loss:\", train_loss_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eb741a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmented transforms ONLY for training set\n",
    "train_transforms_aug = transforms.Compose([\n",
    "    transforms.RandomRotation(50),\n",
    "    transforms.RandomResizedCrop(200, scale=(0.9, 1.0), ratio=(0.9, 1.1)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "# Validation / test transforms stay the same as before\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((200, 200)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "# Re-create datasets with new transforms\n",
    "train_dataset_aug = datasets.ImageFolder(\"data/data/train\", transform=train_transforms_aug)\n",
    "validation_dataset = datasets.ImageFolder(\"data/data/test\", transform=val_transforms)\n",
    "\n",
    "# DataLoaders (same batch size, shuffle settings)\n",
    "train_loader_aug = DataLoader(train_dataset_aug, batch_size=20, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=20, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a2f2de33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.6602, Acc: 0.6613, Val Loss: 0.7089, Val Acc: 0.6866\n",
      "Epoch 2/10, Loss: 0.5547, Acc: 0.7163, Val Loss: 0.6009, Val Acc: 0.7065\n",
      "Epoch 3/10, Loss: 0.5345, Acc: 0.7212, Val Loss: 0.5508, Val Acc: 0.7363\n",
      "Epoch 4/10, Loss: 0.5000, Acc: 0.7600, Val Loss: 0.5279, Val Acc: 0.7463\n",
      "Epoch 5/10, Loss: 0.4832, Acc: 0.7700, Val Loss: 0.5842, Val Acc: 0.7114\n",
      "Epoch 6/10, Loss: 0.4704, Acc: 0.7825, Val Loss: 0.5259, Val Acc: 0.7114\n",
      "Epoch 7/10, Loss: 0.4545, Acc: 0.7775, Val Loss: 0.5017, Val Acc: 0.7910\n",
      "Epoch 8/10, Loss: 0.4481, Acc: 0.7887, Val Loss: 0.5842, Val Acc: 0.6816\n",
      "Epoch 9/10, Loss: 0.4281, Acc: 0.8013, Val Loss: 0.4793, Val Acc: 0.7711\n",
      "Epoch 10/10, Loss: 0.4276, Acc: 0.7975, Val Loss: 0.4887, Val Acc: 0.7562\n",
      "\n",
      "Mean test (validation) loss over augmented training: 0.555260964827751\n"
     ]
    }
   ],
   "source": [
    "# Re-initialize the model, loss function, and optimizer\n",
    "num_epochs_aug = 10\n",
    "\n",
    "history_aug = {'acc': [], 'loss': [], 'val_acc': [], 'val_loss': []}\n",
    "\n",
    "for epoch in range(num_epochs_aug):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    for images, labels in train_loader_aug:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        labels = labels.float().unsqueeze(1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_dataset_aug)\n",
    "    epoch_acc = correct_train / total_train\n",
    "    history_aug['loss'].append(epoch_loss)\n",
    "    history_aug['acc'].append(epoch_acc)\n",
    "\n",
    "    # Validation (test)\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in validation_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            labels = labels.float().unsqueeze(1)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_running_loss += loss.item() * images.size(0)\n",
    "            predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "    val_epoch_loss = val_running_loss / len(validation_dataset)\n",
    "    val_epoch_acc = correct_val / total_val\n",
    "\n",
    "    history_aug['val_loss'].append(val_epoch_loss)\n",
    "    history_aug['val_acc'].append(val_epoch_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs_aug}, \"\n",
    "          f\"Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}, \"\n",
    "          f\"Val Loss: {val_epoch_loss:.4f}, Val Acc: {val_epoch_acc:.4f}\")\n",
    "\n",
    "# Mean TEST (validation) loss over these 10 epochs\n",
    "mean_test_loss = sum(history_aug['val_loss']) / len(history_aug['val_loss'])\n",
    "print(\"Mean test (validation) loss over augmented training:\", mean_test_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0d472463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy for last 5 epochs: [0.7114427860696517, 0.7910447761194029, 0.681592039800995, 0.7711442786069652, 0.7562189054726368]\n",
      "Average test accuracy (epochs 6–10): 0.7422885572139304\n"
     ]
    }
   ],
   "source": [
    "# Validation accuracy for last 5 epochs and their average\n",
    "last5 = history_aug['val_acc'][5:]   # accuracies for epochs 6–10\n",
    "avg_last5 = statistics.mean(last5)\n",
    "\n",
    "print(\"Validation accuracy for last 5 epochs:\", last5)\n",
    "print(\"Average test accuracy (epochs 6–10):\", avg_last5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
