{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "134a99b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mutual_info_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "26536e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset (run only once!)\n",
    "# !wget https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "a1a1b3dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lead_source</th>\n",
       "      <th>industry</th>\n",
       "      <th>number_of_courses_viewed</th>\n",
       "      <th>annual_income</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>location</th>\n",
       "      <th>interaction_count</th>\n",
       "      <th>lead_score</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>79450.0</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>south_america</td>\n",
       "      <td>4</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>social_media</td>\n",
       "      <td>retail</td>\n",
       "      <td>1</td>\n",
       "      <td>46992.0</td>\n",
       "      <td>employed</td>\n",
       "      <td>south_america</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>events</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>5</td>\n",
       "      <td>78796.0</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>australia</td>\n",
       "      <td>3</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>retail</td>\n",
       "      <td>2</td>\n",
       "      <td>83843.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>australia</td>\n",
       "      <td>1</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>referral</td>\n",
       "      <td>education</td>\n",
       "      <td>3</td>\n",
       "      <td>85012.0</td>\n",
       "      <td>self_employed</td>\n",
       "      <td>europe</td>\n",
       "      <td>3</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    lead_source    industry  number_of_courses_viewed  annual_income  \\\n",
       "0      paid_ads         NaN                         1        79450.0   \n",
       "1  social_media      retail                         1        46992.0   \n",
       "2        events  healthcare                         5        78796.0   \n",
       "3      paid_ads      retail                         2        83843.0   \n",
       "4      referral   education                         3        85012.0   \n",
       "\n",
       "  employment_status       location  interaction_count  lead_score  converted  \n",
       "0        unemployed  south_america                  4        0.94          1  \n",
       "1          employed  south_america                  1        0.80          0  \n",
       "2        unemployed      australia                  3        0.69          1  \n",
       "3               NaN      australia                  1        0.87          0  \n",
       "4     self_employed         europe                  3        0.62          1  "
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read csv file\n",
    "df = pd.read_csv('course_lead_scoring.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "97f1d283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lead_source                 128\n",
       "industry                    134\n",
       "number_of_courses_viewed      0\n",
       "annual_income               181\n",
       "employment_status           100\n",
       "location                     63\n",
       "interaction_count             0\n",
       "lead_score                    0\n",
       "converted                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data preparation\n",
    "# Check if the missing values are presented in the features. If there are missing values:\n",
    "df.dtypes\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "40d39069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lead_source                 0\n",
       "industry                    0\n",
       "number_of_courses_viewed    0\n",
       "annual_income               0\n",
       "employment_status           0\n",
       "location                    0\n",
       "interaction_count           0\n",
       "lead_score                  0\n",
       "converted                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For categorical features, replace them with 'NA', and for numerical features, replace with with 0.0\n",
    "df = df.fillna({col: 'NA' for col in df.select_dtypes('object')})\n",
    "df = df.fillna(0.0)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "c169102f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'retail'"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question 1: What is the most frequent observation (mode) for the column industry?\n",
    "df['industry'].mode()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "46ee4212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_of_courses_viewed</th>\n",
       "      <th>annual_income</th>\n",
       "      <th>interaction_count</th>\n",
       "      <th>lead_score</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>number_of_courses_viewed</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.009770</td>\n",
       "      <td>-0.023565</td>\n",
       "      <td>-0.004879</td>\n",
       "      <td>0.435914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>annual_income</th>\n",
       "      <td>0.009770</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027036</td>\n",
       "      <td>0.015610</td>\n",
       "      <td>0.053131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interaction_count</th>\n",
       "      <td>-0.023565</td>\n",
       "      <td>0.027036</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.009888</td>\n",
       "      <td>0.374573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lead_score</th>\n",
       "      <td>-0.004879</td>\n",
       "      <td>0.015610</td>\n",
       "      <td>0.009888</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.193673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>converted</th>\n",
       "      <td>0.435914</td>\n",
       "      <td>0.053131</td>\n",
       "      <td>0.374573</td>\n",
       "      <td>0.193673</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          number_of_courses_viewed  annual_income  \\\n",
       "number_of_courses_viewed                  1.000000       0.009770   \n",
       "annual_income                             0.009770       1.000000   \n",
       "interaction_count                        -0.023565       0.027036   \n",
       "lead_score                               -0.004879       0.015610   \n",
       "converted                                 0.435914       0.053131   \n",
       "\n",
       "                          interaction_count  lead_score  converted  \n",
       "number_of_courses_viewed          -0.023565   -0.004879   0.435914  \n",
       "annual_income                      0.027036    0.015610   0.053131  \n",
       "interaction_count                  1.000000    0.009888   0.374573  \n",
       "lead_score                         0.009888    1.000000   0.193673  \n",
       "converted                          0.374573    0.193673   1.000000  "
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question 2: Create the correlation matrix for the numerical features of your dataset. In a correlation matrix, you compute the correlation coefficient between every pair of features.\n",
    "# What are the two features that have the biggest correlation?\n",
    "num_df = df.select_dtypes(include=['number'])\n",
    "corr = num_df.corr()\n",
    "corr\n",
    "\n",
    "# -> annual_income and interaction_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "d3a98042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5998632010943913, 0.1997264021887825, 0.20041039671682626)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split your data in train/val/test sets with 60%/20%/20% distribution.\n",
    "# Use Scikit-Learn for that (the train_test_split function) and set the seed to 42.\n",
    "# Make sure that the target value y is not in your dataframe.\n",
    "X = df.drop(columns=['converted'])\n",
    "y = df['converted']\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "len(X_train) / len(df), len(X_val) / len(df), len(X_test) / len(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "396a9251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lead_source': 0.03,\n",
       " 'industry': 0.02,\n",
       " 'employment_status': 0.02,\n",
       " 'location': 0.0}"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question 3: Calculate the mutual information score between y and other categorical variables in the dataset. \n",
    "# Use the training set only. \n",
    "# Round the scores to 2 decimals using round(score, 2).\n",
    "cat_cols = X_train.select_dtypes(include=['object']).columns\n",
    "\n",
    "mi_scores = {}\n",
    "\n",
    "for col in cat_cols:\n",
    "    score = mutual_info_score(X_train[col], y_train)\n",
    "    mi_scores[col] = round(score, 2)\n",
    "\n",
    "mi_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "6fc467d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question 4: \n",
    "'''\n",
    "Now let's train a logistic regression.\n",
    "Remember that we have several categorical variables in the dataset. Include them using one-hot encoding.\n",
    "Fit the model on the training dataset.\n",
    "To make sure the results are reproducible across different versions of Scikit-Learn, fit the model with these parameters:\n",
    "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "Calculate the accuracy on the validation dataset and round it to 2 decimal digits.\n",
    "'''\n",
    "# One-hot coding for categorical features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)\n",
    "    ],\n",
    "    remainder='passthrough'  # Keep all other columns\n",
    ")\n",
    "\n",
    "# Transform the datasets\n",
    "X_train_enc = preprocessor.fit_transform(X_train)\n",
    "X_val_enc = preprocessor.transform(X_val)\n",
    "X_test_enc = preprocessor.transform(X_test)\n",
    "\n",
    "# Train logistic regression model\n",
    "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "model.fit(X_train_enc, y_train)\n",
    "\n",
    "# Predict on validation set\n",
    "y_val_pred = model.predict(X_val_enc)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_val, y_val_pred)\n",
    "round(accuracy, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "9fdc8617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "industry: 0.0\n",
      "employment_status: -0.003424657534246589\n",
      "lead_score: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Question 5\n",
    "'''\n",
    "Let's find the least useful feature using the feature elimination technique.\n",
    "Train a model using the same features and parameters as in Q4 (without rounding).\n",
    "Now exclude each feature from this set and train a model without it. Record the accuracy for each model.\n",
    "For each feature, calculate the difference between the original accuracy and the accuracy without the feature.\n",
    "Which of following feature has the smallest difference?\n",
    "'''\n",
    "# Leave-one-feature-out: drop each feature, retrain, and record accuracy difference\n",
    "diffs = {}\n",
    "\n",
    "for feat in list(X_train.columns):\n",
    "    X_train_sub = X_train.drop(columns=[feat])\n",
    "    X_val_sub = X_val.drop(columns=[feat])\n",
    "\n",
    "    # Update categorical columns for this run\n",
    "    cat_sub = [c for c in cat_cols if c != feat]\n",
    "\n",
    "    preproc_sub = ColumnTransformer(\n",
    "        transformers=[('cat', OneHotEncoder(handle_unknown='ignore'), cat_sub)],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "\n",
    "    X_train_enc_sub = preproc_sub.fit_transform(X_train_sub)\n",
    "    X_val_enc_sub = preproc_sub.transform(X_val_sub)\n",
    "\n",
    "    model_sub = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "    model_sub.fit(X_train_enc_sub, y_train)\n",
    "\n",
    "    y_val_pred_sub = model_sub.predict(X_val_enc_sub)\n",
    "    accuracy_sub = accuracy_score(y_val, y_val_pred_sub)\n",
    "    \n",
    "    # Store the difference in accuracy\n",
    "    diffs[feat] = accuracy - accuracy_sub\n",
    "\n",
    "\n",
    "# Print the accuracy difference for the requested features\n",
    "focus = ['industry', 'employment_status', 'lead_score']\n",
    "for f in focus:\n",
    "    print(f\"{f}: {diffs[f]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "570630e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.01: 0.743, 0.1: 0.743, 1: 0.743, 10: 0.743, 100: 0.743}"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question 6\n",
    "'''\n",
    "Now let's train a regularized logistic regression.\n",
    "Let's try the following values of the parameter C: [0.01, 0.1, 1, 10, 100].\n",
    "Train models using all the features as in Q4.\n",
    "Calculate the accuracy on the validation dataset and round it to 3 decimal digits.\n",
    "Which of these C leads to the best accuracy on the validation set?\n",
    "Note: If there are multiple options, select the smallest C\n",
    "'''\n",
    "\n",
    "# Try different values of C for regularized logistic regression\n",
    "C_values = [0.01, 0.1, 1, 10, 100]\n",
    "val_accuracies = {}\n",
    "\n",
    "for c in C_values:\n",
    "    model = LogisticRegression(solver='liblinear', C=c, max_iter=1000, random_state=42)\n",
    "    model.fit(X_train_enc, y_train)\n",
    "    y_val_pred = model.predict(X_val_enc)\n",
    "    acc = accuracy_score(y_val, y_val_pred)\n",
    "    val_accuracies[c] = round(acc, 3)\n",
    "\n",
    "val_accuracies\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
